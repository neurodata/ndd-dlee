# Abstract

Networks are a very effective way of representing complex data structures such as neural connectomes. When working with a large collection of networks, graphs kernels measure how similar or dissimilar one graph is to another, which can help us with clustering disorganized data points into a lower dimensional structure that we can visualize and understand. There are many complex graph kernels that have been developed, but they can be computationally expensive when working with large datasets. Here we build ”simple” kernels that require much less computational power and provide an overview of their performances on weighted matched and unmatched networks. We use the following network properties for the kernels: density, average edge weight, average of the adjacency matrix, node degrees, node strengths, and edge weights. We first calculate the discriminability of each kernel by generating a dissimilarity matrix, then we evaluate the performances of agglomerative clustering, kmeans clustering, and gaussian mixture model clustering on each dissimilarity matrix using the adjusted rand index (ARI). We compare the results to those based on the distance between their Omnibus embeddings (for matched networks), the difference between their latent distribution test statistics (for unmatched networks), and the Laplacian spectral distance (for both matched and unmatched networks) as metrics for comparison against well-established and more complex kernels. We find that overall, these kernels perform much better with matched networks than with unmatched networks. Within the matched networks, kernels based on the known matching of nodes (edge weights, node strengths, node degrees, and Omnibus embeddings) generally show higher discriminability and ARI values than kernels based on global properties that do not assume any node matching (density, average edge weight, average of the adjacency matrix, and Laplacian spectral distance), with Omnibus embeddings being the highest performing metric. Whereas within unmatched networks, we observe the opposite, with Laplacian spectral distance being the highest performing metric and kernels based on global properties performing better than the other kernels, including the kernel based on the difference between latent distribution test statistics, which suggests that kernel performance may depend more on network properties than kernel complexity. More datasets should be explored to solidfy any identified trends, but these findings suggest that simple kernels can be a much faster yet still relatively effective way of measuring dissimilarity between graphs.